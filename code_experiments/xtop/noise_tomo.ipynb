{
 "metadata": {
  "name": "",
  "signature": "sha256:e13ff67d14f1edfbf4718a97a847fb62808a5db168da6f813559fa703332e7f2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#\u0421\u043f\u0438\u0441\u043e\u043a \u0442\u043e\u0433\u043e \u0447\u0442\u043e \u043d\u0430\u0434\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c:\n",
      "\n",
      "* \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0437\u0430\u0448\u0443\u043c\u043b\u0451\u043d\u043d\u044b\u0445 \u0441\u0438\u043d\u043e\u0433\u0440\u0430\u043c\u043c\n",
      "    * \u0421\u0442\u0430\u043d\u0434\u0430\u0440\u043d\u044b\u0435 \u0444\u0430\u043d\u0442\u043e\u043c\u044b\n",
      "        * \u041c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0428\u0435\u043f-\u043b\u043e\u0433\u0430\u043d\n",
      "        * \u041b\u0435\u043d\u0430\n",
      "        * \u0424\u0430\u043d\u0442\u043e\u043c\u044b \u0434\u043b\u044f \u0444\u0430\u0437\u043e\u0432\u043e\u0433\u043e \u043a\u043e\u043d\u0442\u0440\u0430\u0441\u0442\u0430\n",
      "    * \u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0435 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u0438\u0437\u043b\u0443\u0447\u0435\u043d\u0438\u044f\n",
      "        * \u0422\u0440\u0443\u0431\u043a\u0430 \n",
      "        * \u0421\u0418\n",
      "* \u0420\u0435\u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u044f \u0437\u0430\u0448\u0443\u043c\u043b\u0451\u043d\u043d\u044b\u0445 \u0441\u0438\u043d\u043e\u0433\u0440\u0430\u043c\u043c \u0440\u0430\u0437\u043d\u044b\u043c\u0438 \u043c\u0435\u0442\u043e\u0434\u0430\u043c\u0438\n",
      "    * FBP\n",
      "    * SART\n",
      "    * SART + \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f\n",
      "    \n",
      "* \u0421\u043e\u043f\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432\n",
      "    * \u041f\u043e\u0433\u043b\u043e\u0449\u0435\u043d\u0438\u0435 \u0441\u0430\u043c\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\n",
      "    * \u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432:\n",
      "        * \u0427\u0438\u0441\u043b\u043e \u043f\u0440\u043e\u0435\u043a\u0446\u0438\u0439\n",
      "        * \u0427\u0438\u0441\u043b\u043e \u043a\u0430\u043d\u0430\u043b\u043e\u0432 \u0434\u0435\u0442\u0435\u043a\u0442\u043e\u0440\u0430\n",
      "        * \u0412\u0440\u0435\u043c\u044f \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u043f\u0440\u043e\u0435\u043a\u0446\u0438\u0438\n",
      "        \n",
      "    * \u0421\u044a\u0451\u043c\u043a\u0430 \u0441 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u043e\u0439 \u0438 \u0431\u0435\u0437 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438\n",
      "    * \u041e\u0448\u0438\u0431\u043a\u0438 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u0438\u044f \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\n",
      "        * \u0423\u0433\u043b\u044b \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u0430\n",
      "        * \u0421\u0434\u0432\u0438\u0433 \u043e\u0441\u0438\n",
      "        * \u041e\u0448\u0438\u0431\u043a\u0438 \u0434\u0435\u0442\u0435\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\n",
      "        * \u041f\u043e\u043b\u0435 \u0437\u0440\u0435\u043d\u0438\u044f\n",
      "* TODO:\n",
      "    * \u0418\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0440\u0435\u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0439 \u0438 \u0440\u0435\u0433\u0438\u043e\u043d\u0430\n",
      "    * \u0421\u0442\u0430\u0442\u0438\u0442\u0441\u0442\u0438\u043a\u0430 \u0432\u0441\u0435\u0445 \u0442\u0438\u043f\u043e\u0432 \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044e \u0438 \u043f\u043e \u0440\u0435\u0433\u0438\u043e\u043d\u0443  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython import parallel\n",
      "parallel_client = parallel.Client()\n",
      "parallel_view = parallel_client.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "import os\n",
      "import sys\n",
      "\n",
      "sys.path.insert(0,os.path.join('..','..'))\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pylab as plt\n",
      "import h5py\n",
      "import skimage\n",
      "from skimage.transform import radon, iradon, iradon_sart\n",
      "import cv2\n",
      "import fastlib.utils.phantom as phantom\n",
      "import fastlib.utils.mssim as mssim\n",
      "from fastlib.imageprocessing.ispmd import project, rotate_square, back_project\n",
      "from pprint import pprint\n",
      "from __future__ import division, print_function\n",
      "from pprint import pprint\n",
      "import hashlib\n",
      "\n",
      "import cPickle as pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def get_phantom_2d(name, shape, max_value = None, working_dir = None):\n",
      "    \"\"\"\n",
      "    Return phantom. First try to search it in cache file phantom_cache.h5.\n",
      "    \n",
      "    :param name: 'modified_shepp_logan', 'lena'\n",
      "    :param shape: phantom size\n",
      "    :type shape: int\n",
      "    :param max_value: max value\n",
      "    :return: 2d array - phantom\n",
      "    \"\"\"\n",
      "    if working_dir is None:\n",
      "        phantoms_dir = 'phantoms_cache'\n",
      "    else:\n",
      "        phantoms_dir = os.path.join(working_dir, 'phantoms_cache')\n",
      "        \n",
      "    try:\n",
      "        os.mkdir(phantoms_dir)\n",
      "    except OSError:\n",
      "        pass\n",
      "    \n",
      "    phantom_string = '/'.join([name,str(shape)])\n",
      "    \n",
      "    phantoms_file = os.path.join(phantoms_dir,phantom_string.replace('/','_')+'.h5')\n",
      "\n",
      "    print(phantoms_file)\n",
      "    #try find phanom in cache\n",
      "    with h5py.File(phantoms_file) as h5:\n",
      "        if phantom_string in h5:\n",
      "            res = h5[phantom_string].value\n",
      "            if not max_value is None:\n",
      "                res = res*max_value\n",
      "            return res\n",
      "        \n",
      "    #calculate phantom and store it in cache    \n",
      "    if name == 'modified_shepp_logan':\n",
      "        p = phantom.modified_shepp_logan((shape,shape,3), dtype=np.float32)\n",
      "        p = np.array(np.squeeze(p[:,:,1]), dtype = 'float32')\n",
      "        res = (p-p.min())/(p.max()-p.min())\n",
      "    elif name == 'lena':\n",
      "        p = sp.misc.lena().astype('float32')\n",
      "        p = cv2.resize(p,(shape, shape))\n",
      "        res = (p-p.min())/(p.max()-p.min())\n",
      "        \n",
      "    with h5py.File(phantoms_file) as h5:\n",
      "        h5[phantom_string] = res\n",
      "    \n",
      "    if not max_value is None:\n",
      "        res = res*max_value\n",
      "        \n",
      "    return res\n",
      "def cv_rotate(x, angle):\n",
      "    \"\"\"\n",
      "    Rotate square array using OpenCV2 around center of the array\n",
      "    :param x: 2d numpy array\n",
      "    :param angle: angle in degrees\n",
      "    :return: rotated array\n",
      "    \"\"\"\n",
      "    x_center = tuple(np.array((x.shape[1], x.shape[0]), dtype='float32') / 2.0-0.5)\n",
      "    rot_mat = cv2.getRotationMatrix2D(x_center, angle, 1.0)\n",
      "    xro = cv2.warpAffine(x, rot_mat, (x.shape[1], x.shape[0]), flags=cv2.INTER_LINEAR)\n",
      "    return xro\n",
      "\n",
      "\n",
      "def cv_project(src):\n",
      "    \"\"\"\n",
      "    Project 2D array to 1D array\n",
      "\n",
      "    :param src: 2d numpy array.\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    return np.squeeze(cv2.reduce(src, dim=1, rtype=cv2.cv.CV_REDUCE_SUM))\n",
      "\n",
      "\n",
      "def cv_backproject(src):\n",
      "    \"\"\"\n",
      "    Back project 1d array to 2d array.\n",
      "\n",
      "    :param src: 1d numpy array\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    ntimes = len(src)\n",
      "    tmp_array = src / float(ntimes)\n",
      "    return cv2.repeat(tmp_array,1,ntimes)\n",
      "\n",
      "def make_zeroses_circle(sq_image):\n",
      "    output_size = sq_image.shape[0]\n",
      "    [X, Y] = np.mgrid[0:output_size, 0:output_size]\n",
      "    xpr = X - int(output_size) // 2\n",
      "    ypr = Y - int(output_size) // 2\n",
      "    radius = output_size // 2\n",
      "    reconstruction_circle = (xpr**2 + ypr**2) <= radius**2\n",
      "    sq_image[~reconstruction_circle] = 0.\n",
      "\n",
      "def my_sart(sinogram, angles, filter_size = None):\n",
      "    \"\"\"\n",
      "    SART tomography reconstruction.\n",
      "\n",
      "    :param sinogram: 2d array (s[:,i] - i-th projection)\n",
      "    :param angles:  1d array of angles\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    sinogram = sinogram.astype(np.float32)\n",
      "    reconst_shape = np.array(sinogram.shape[0], dtype='int32')\n",
      "    tomo_rec = np.zeros((reconst_shape, reconst_shape), dtype='float32')\n",
      "    tmp_backproj = np.zeros_like(tomo_rec)\n",
      "    tmp_rot = np.zeros_like(tomo_rec)\n",
      "    for coeff in [0.8, 0.3, 0.3]:  # set relaxation coeffitients here (one per iteration)\n",
      "        shuffle_iang = np.arange(len(angles))\n",
      "        np.random.shuffle(shuffle_iang)\n",
      "        for enum_iang,iang in enumerate(shuffle_iang):\n",
      "            tmp_rot = rotate_square(tomo_rec, angles[iang])\n",
      "            tmp_proj = sinogram[:, iang] - project(tmp_rot)\n",
      "            tmp_backproj = back_project(tmp_proj * coeff)\n",
      "            tmp_rot = rotate_square(tmp_backproj, -angles[iang])\n",
      "            tomo_rec+= tmp_rot\n",
      "            if enum_iang % len(shuffle_iang)//3 == 0:\n",
      "                if not filter_size is None:\n",
      "                    tomo_rec = 0.5*(cv2.medianBlur(tomo_rec,filter_size)+tomo_rec)\n",
      "                make_zeroses_circle(tomo_rec)\n",
      "                \n",
      "        tomo_rec -= 0.5 * tomo_rec * (tomo_rec < 0)\n",
      "        if not filter_size is None:\n",
      "            tomo_rec = cv2.medianBlur(tomo_rec,filter_size)\n",
      "        make_zeroses_circle(tomo_rec)\n",
      "    return tomo_rec.T*sinogram.shape[0]\n",
      "\n",
      "def fbp(sinogram, angles):\n",
      "    res = iradon(sinogram, angles, circle=True)\n",
      "    return res*sinogram.shape[0]\n",
      "\n",
      "def show_result(res):\n",
      "    size = res.shape[0]\n",
      "    plt.figure(figsize=(15,10))\n",
      "    plt.subplot(121)\n",
      "    plt.imshow(res)\n",
      "    plt.gray()\n",
      "    plt.colorbar(orientation = 'horizontal')\n",
      "    plt.subplot(122)\n",
      "    plt.imshow(res[int(size*0.417):int(size*0.556),int(size*0.222):int(size*0.361)], interpolation='nearest')\n",
      "    plt.gray()\n",
      "    plt.colorbar(orientation = 'horizontal')\n",
      "    \n",
      "def pad_phantom(image):\n",
      "    \"\"\"\n",
      "    Pad phantom to zeros to keep it in circle\n",
      "    \"\"\"\n",
      "    diagonal = np.sqrt(2) * max(image.shape)\n",
      "    pad = [int(np.ceil(diagonal - s)) for s in image.shape]\n",
      "    new_center = [(s + p) // 2 for s, p in zip(image.shape, pad)]\n",
      "    old_center = [s // 2 for s in image.shape]\n",
      "    pad_before = [nc - oc for oc, nc in zip(old_center, new_center)]\n",
      "    pad_width = [(pb, p - pb) for pb, p in zip(pad_before, pad)]\n",
      "    padded_image = skimage.util.pad(image, pad_width, mode='constant',\n",
      "                            constant_values=0)\n",
      "    return padded_image\n",
      "\n",
      "def add_noise(sinogram, mean_intesity):\n",
      "    noise = np.random.poisson(mean_intesity, size = sinogram.shape)\n",
      "    noise[noise<=0]=1\n",
      "    normed_noise  = noise/mean_intesity\n",
      "    noised_sinogram = -np.log(normed_noise)+sinogram\n",
      "    noised_sinogram[noised_sinogram<=0]=0\n",
      "    return noised_sinogram\n",
      "\n",
      "def build_sinogram(image, angles, photons = None, working_dir = None):\n",
      "    \"\"\"\n",
      "    Build sinogram and make normalizalization\n",
      "    :param image: source image\n",
      "    :param angles: angles\n",
      "    :param photons: mean number of photons in direct beam per short to all detector\n",
      "    :return: sinogram\n",
      "    \"\"\"\n",
      "    if not working_dir is None:\n",
      "        image_hash = hashlib.sha256(image.tostring()).hexdigest()\n",
      "        angles_hash = hashlib.sha256(angles.tostring()).hexdigest()\n",
      "        sinogram_hash = image_hash+angles_hash\n",
      "        sinograms_dir = os.path.join(working_dir, 'sinograms_cache')\n",
      "        \n",
      "        try:\n",
      "            os.mkdir(sinograms_dir)\n",
      "        except OSError:\n",
      "            pass\n",
      "        sinogram_file = os.path.join(sinograms_dir, 'sinogram_'+sinogram_hash+'.h5')\n",
      "        \n",
      "        if os.path.exists(sinogram_file):\n",
      "            with h5py.File(sinogram_file) as h5:\n",
      "                clear_sinogram = h5[sinogram_hash].value\n",
      "        else:\n",
      "            clear_sinogram = radon(image, angles)            \n",
      "            with h5py.File(sinogram_file,'w') as h5:\n",
      "                h5[sinogram_hash] = clear_sinogram\n",
      "    else:   \n",
      "        clear_sinogram = radon(image, angles)\n",
      "    \n",
      "    chanels_count = clear_sinogram.shape[0]\n",
      "    clear_sinogram = clear_sinogram*(1./chanels_count)\n",
      "    \n",
      "    print('Number of chanels {}'.format(chanels_count))\n",
      "    if photons is None:\n",
      "        res = clear_sinogram\n",
      "    else:\n",
      "        mean_photons_per_pixel = photons//chanels_count\n",
      "        print('Mean number of photons per chanel {}'.format(mean_photons_per_pixel))\n",
      "        noised_sinogram = add_noise(clear_sinogram, mean_photons_per_pixel)\n",
      "        res = noised_sinogram\n",
      "    return res\n",
      "\n",
      "def image_std(image1, image2):\n",
      "    return np.sqrt(np.mean(np.abs(image1[:]-image2[:])**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phantom_name = 'modified_shepp_logan'\n",
      "#phantom_name = 'lena'\n",
      "angles = np.arange(0,180,0.1)\n",
      "photons = 1e7\n",
      "\n",
      "my_phantom = get_phantom_2d(phantom_name, 512, 2)\n",
      "paded_phantom = pad_phantom(my_phantom)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_result(paded_phantom)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clear_sinogram = build_sinogram(my_phantom, angles)\n",
      "noised_sinogram = build_sinogram(my_phantom, angles, photons = photons)\n",
      "\n",
      "plt.figure(figsize=(12,12))\n",
      "plt.subplot(221)\n",
      "plt.imshow(clear_sinogram)\n",
      "plt.axis('tight')\n",
      "plt.colorbar(orientation = 'horizontal')\n",
      "\n",
      "plt.subplot(223)\n",
      "plt.plot(clear_sinogram[:,100])\n",
      "plt.axis('tight')\n",
      "plt.subplot(224)\n",
      "plt.plot(add_noise(noised_sinogram, photons)[:,100])\n",
      "plt.axis('tight')\n",
      "plt.subplot(222)\n",
      "plt.imshow(add_noise(noised_sinogram, photons))\n",
      "plt.axis('tight')\n",
      "plt.colorbar(orientation = 'horizontal')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rec_fbp = fbp(noised_sinogram, angles)\n",
      "show_result(rec_fbp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smooth_rec_fbp = cv2.medianBlur(np.array(rec_fbp).astype('float32'),5)\n",
      "show_result(smooth_rec_fbp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rec_sart1 = iradon_sart(sinogram_sp, angles)\n",
      "# rec_sart2 = iradon_sart(sinogram_sp, angles, image=rec_sart1)\n",
      "# rec_sart3 = iradon_sart(sinogram_sp, angles, image=rec_sart2)\n",
      "# show_result(rec_sart3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rec_my = my_sart(noised_sinogram, angles,5)\n",
      "show_result(rec_my)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = {'original': {'data':paded_phantom},\n",
      "        #'rec_sart3':rec_sart3,\n",
      "        'smooth_rec_fbp': {'data':smooth_rec_fbp},\n",
      "        'rec_my': {'data':rec_my, 'style':{'color':'k'}},\n",
      "        'rec_fbp': {'data':rec_fbp}\n",
      "        }\n",
      "\n",
      "size = data['original']['data'].shape[0]\n",
      "x_range = range(int(size*0.4),int(size*0.6))\n",
      "y_range = int(size*0.292)\n",
      "\n",
      "plt.figure(figsize=(16,5))\n",
      "\n",
      "plt.subplot(131)\n",
      "for k,v in data.iteritems():\n",
      "    if 'style' in v:\n",
      "        kwords = v['style']\n",
      "    else:\n",
      "        kwords = {}\n",
      "        \n",
      "    plt.plot(v['data'][x_range, y_range], label = k,**kwords)\n",
      "    plt.hold(True)\n",
      "\n",
      "plt.grid()\n",
      "plt.legend()\n",
      "\n",
      "plt.subplot(132)\n",
      "orig_data = data['original']['data']\n",
      "for k,v in data.iteritems():\n",
      "    if 'style' in v:\n",
      "        kwords = v['style']\n",
      "    else:\n",
      "        kwords = {}\n",
      "        \n",
      "    if not k == 'original':\n",
      "        plt.plot((v['data']-orig_data)[x_range, y_range], \n",
      "                 label = '{} {:0.3}'.format(k, image_std(v['data'],orig_data)),\n",
      "                 **kwords)\n",
      "        plt.hold(True)\n",
      "\n",
      "plt.grid()\n",
      "plt.legend()\n",
      "\n",
      "plt.subplot(133)\n",
      "plt.imshow(data['original']['data'])\n",
      "plt.hold(True)\n",
      "if isinstance(y_range, int) or len(y_range) == 1:\n",
      "    x_plot = x_range\n",
      "    y_plot = y_range*np.ones_like(x_range)\n",
      "    \n",
      "elif isinstance(x_range, int) or len(x_range) == 1:\n",
      "    x_plot = x_range*np.ones_like(y_range)\n",
      "    y_plot = y_range\n",
      "else:\n",
      "    x_plot = x_range\n",
      "    y_plot = y_range\n",
      "\n",
      "#show position on phantom\n",
      "plt.plot(y_plot,x_plot)\n",
      "\n",
      "plt.figure(figsize=(15,8))\n",
      "keys = ['rec_my', 'rec_fbp']\n",
      "for ik, k in enumerate(keys):\n",
      "    plt.subplot(100+10*len(keys)+ik)\n",
      "    plt.imshow(mssim.MSSIM(data['original']['data'], data[k]['data']))\n",
      "    plt.title('{}, ssim = {}'.format(k,mssim.SSIM(data['original']['data'], data[k]['data'])))\n",
      "    plt.colorbar(orientation = 'horizontal')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0435 \u0432\u044b\u0432\u043e\u0434\u044b\n",
      "\n",
      "* \u041d\u0430 \u0444\u0430\u043d\u0442\u043e\u043c\u0435 \u041b\u0435\u043d\u0430 \u043f\u0440\u0438 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u0447\u0438\u0441\u043b\u0435 \u0443\u0433\u043b\u043e\u0432 \u0430\u043b\u0433\u0435\u0431\u0440\u0430\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043c\u0435\u0442\u043e\u0434\u044b \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u043b\u0443\u0447\u0448\u0435 FBP (\u043d\u0430 1D \u0441\u0440\u0435\u0437\u0435) "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!rm phantom_cache.h5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config = {}\n",
      "config['working_dir'] = '/home/makov/tmp/xtop'\n",
      "config['phantom_names'] = ['modified_shepp_logan',] # 'lena']\n",
      "config['phantom_maxima'] = [1,2]\n",
      "config['phantom_sizes'] = [128,256,512, 768, 1024]\n",
      "config['angles'] = [np.arange(0,180,step) for step in 4,2,1,0.5, 0.3, 0.2]\n",
      "\n",
      "len_angs = [len(a) for a in config['angles']]\n",
      "total_photons = [1e6, 1e9, 1e12]\n",
      "photons_per_projection = [t/a for a in len_angs for t in total_photons]\n",
      "photons_per_projection.append(None)\n",
      "#print(photons_per_projection)\n",
      "config['photons'] = photons_per_projection\n",
      "config['filter_sizes'] = [None,3,5]\n",
      "\n",
      "phantoms =[]\n",
      "\n",
      "for phantom_name in config['phantom_names'] : \n",
      "    for phantom_size in config['phantom_sizes']:\n",
      "        p = {'phantom_name': phantom_name,\n",
      "            'phantom_size': phantom_size,\n",
      "            'working_dir': config['working_dir']}\n",
      "        phantoms.append(p)\n",
      "\n",
      "pprint(len(phantoms))\n",
      "\n",
      "\n",
      "sinograms =[]\n",
      "\n",
      "for phantom_name in config['phantom_names'] :    \n",
      "        for phantom_size in config['phantom_sizes']:\n",
      "            for angles in config['angles']:\n",
      "                p = {'phantom_name': phantom_name,\n",
      "                     'phantom_size': phantom_size,\n",
      "                     'angles': angles,\n",
      "                     'working_dir': config['working_dir']}\n",
      "                sinograms.append(p)\n",
      "\n",
      "pprint(len(sinograms))\n",
      "\n",
      "params = []\n",
      "\n",
      "for phantom_name in config['phantom_names'] :    \n",
      "    for phantom_maximum in config['phantom_maxima']:\n",
      "        for phantom_size in config['phantom_sizes']:\n",
      "            for angles in config['angles']:\n",
      "                for photons in config['photons']:\n",
      "                    for filter_size in config['filter_sizes']:\n",
      "                        p = {'phantom_name': phantom_name,\n",
      "                             'phantom_maximum': phantom_maximum,\n",
      "                             'phantom_size': phantom_size,\n",
      "                             'angles': angles,\n",
      "                             'photons': photons,\n",
      "                             'filter_size': filter_size,\n",
      "                             'working_dir': config['working_dir']}\n",
      "                        params.append(p)\n",
      "\n",
      "pprint(len(params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@parallel_view.parallel(block=True)\n",
      "def f(x): return 2*x\n",
      "\n",
      "result = f.map(range(10))\n",
      "print(\"Using a parallel function: \", result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@parallel_view.parallel(block=True)\n",
      "def generate_phantoms(params):\n",
      "    my_phantom = get_phantom_2d(params['phantom_name'], \n",
      "                                params['phantom_size'],\n",
      "                                1,\n",
      "                                params['working_dir'])\n",
      "    #paded_phantom = pad_phantom(my_phantom)\n",
      "    return ' '.join([str(s) for s in [params['phantom_name'], params['phantom_size']]])\n",
      "\n",
      "result = generate_phantoms.map(phantoms)\n",
      "print(\"Using a parallel function: \", '\\n'.join(result))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@parallel_view.parallel(block=True)\n",
      "def generate_sinograms(params):\n",
      "    my_phantom = get_phantom_2d(params['phantom_name'], \n",
      "                                params['phantom_size'],\n",
      "                                1,\n",
      "                                params['working_dir'])\n",
      "    my_sinogram = build_sinogram(my_phantom, params['angles'], photons=None, working_dir=params['working_dir'])\n",
      "    #paded_phantom = pad_phantom(my_phantom)\n",
      "    return ' '.join([str(s) for s in [params['phantom_name'], params['phantom_size'], len(params['angles'])]])\n",
      "\n",
      "result = generate_sinograms.map(sinograms)\n",
      "print(\"Using a parallel function: \", '\\n'.join(result))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@parallel_view.parallel(block=True)\n",
      "def calculate_tomo(params):\n",
      "    def save_dict(group, dic):\n",
      "        for k,v in dic.iteritems():\n",
      "            try:\n",
      "                group[k] = v\n",
      "            except TypeError:\n",
      "                if isinstance(v,dict):\n",
      "                    tmp_grp = group.create_group(k)\n",
      "                    save_dict(tmp_grp, v)\n",
      "                else:\n",
      "                    group[k] = str(v)\n",
      "    \n",
      "    # build file name and check that file not exist\n",
      "    out_dir = os.path.join(params['working_dir'],'reconstructions')\n",
      "    uniq_string = hashlib.sha256('_'.join([str(s) for s in params.values()])).hexdigest()\n",
      "    out_file = os.path.join(out_dir,'tomo_'+uniq_string+'.h5')\n",
      "    try:\n",
      "        os.mkdir(out_dir)\n",
      "    except OSError:\n",
      "        pass\n",
      "    \n",
      "    if os.path.exists(out_file):\n",
      "        return 'Skip: {}'.format(out_file)\n",
      "    \n",
      "    #build phantom and sinograms\n",
      "    my_phantom = get_phantom_2d(params['phantom_name'], \n",
      "                                params['phantom_size'],\n",
      "                                params['phantom_maximum'],\n",
      "                                params['working_dir'])\n",
      "    \n",
      "    my_phantom = pad_phantom(my_phantom)\n",
      "    \n",
      "    noised_sinogram = build_sinogram(my_phantom, params['angles'], \n",
      "                                     photons = params['photons'], working_dir =params['working_dir'])\n",
      "    \n",
      "    #build reconstructions\n",
      "    rec_fbp = fbp(noised_sinogram, params['angles'])\n",
      "    if not params['filter_size'] is None:\n",
      "              smooth_rec_fbp = cv2.medianBlur(np.array(rec_fbp).astype('float32'),params['filter_size'])\n",
      "    else:\n",
      "        smooth_rec_fbp = rec_fbp \n",
      "    rec_my = my_sart(noised_sinogram, params['angles'], params['filter_size'])\n",
      "    \n",
      "    #save results\n",
      "    res = {'params': params,\n",
      "           'noised_sinogram': noised_sinogram,\n",
      "           'fbp': rec_fbp,\n",
      "           'smoothed_fbp': smooth_rec_fbp,\n",
      "           'sart': rec_my,\n",
      "           'phantom': my_phantom\n",
      "           }\n",
      "       \n",
      "    with h5py.File(out_file, 'w') as h5:\n",
      "        save_dict(h5, res)\n",
      "                \n",
      "    return 'Done: {}'.format(out_file)\n",
      "\n",
      "result = calculate_tomo.map(params)\n",
      "print(\"Using a parallel function: \\n\", '\\n'.join(result))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "\n",
      "def load_hdf5_tree(group):\n",
      "    \"\"\"convert h5file to the tree\"\"\"\n",
      "    out_dict = {}\n",
      "\n",
      "    def add_item(name, obj):\n",
      "        if not isinstance(obj, h5py.Group):\n",
      "            tmp = {}\n",
      "            if obj.value == 'None':\n",
      "                tmp[name.encode()] = None\n",
      "            else:\n",
      "                tmp[name.encode()] = obj.value\n",
      "            out_dict.update(tmp)\n",
      "\n",
      "    group.visititems(add_item)\n",
      "\n",
      "    return out_dict\n",
      "\n",
      "def collect_datasets(working_dir, files_prefix):\n",
      "    files = glob(os.path.join(working_dir,'reconstructions',files_prefix+'*.h5'))\n",
      "    print('Found {} files'.format(len(files)))\n",
      "    res = {}\n",
      "    for f in files:\n",
      "        with h5py.File(f,'r') as h5:\n",
      "            if 'params' in h5:\n",
      "                res[f] = load_hdf5_tree(h5['params'])\n",
      "                \n",
      "    return res\n",
      "\n",
      "tomo_collection = collect_datasets(config['working_dir'],'tomo_')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_dict_values(d, key, reduce_function = None):\n",
      "    res = [x[key] for x in d.values()]\n",
      "    \n",
      "    if not reduce_function is None:\n",
      "        res = [reduce_function(x) for x in res]\n",
      "    res = sorted(list(set(res)))\n",
      "    return res\n",
      "\n",
      "filter_sizes = find_dict_values(tomo_collection, 'filter_size')\n",
      "phantom_maxima = find_dict_values(tomo_collection, 'phantom_maximum')\n",
      "phantom_names = find_dict_values(tomo_collection, 'phantom_name')\n",
      "phantom_sizes = find_dict_values(tomo_collection, 'phantom_size')\n",
      "photons = find_dict_values(tomo_collection, 'photons')\n",
      "angles_count = find_dict_values(tomo_collection, 'angles',len)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interactive\n",
      "from IPython.html import widgets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_files(key, value, reduce_func = None):\n",
      "    if reduce_func is None:\n",
      "        files = [k for (k,v) in tomo_collection.iteritems() if v[key] == value]\n",
      "    else:\n",
      "        files = [k for (k,v) in tomo_collection.iteritems() if reduce_func(v[key]) == value]\n",
      "    return files\n",
      "\n",
      "def find_tomo_file(phantom_name, phantom_size, phantom_maximum, filter_size, photons, angles_count):\n",
      "    files = set(get_files('phantom_name', phantom_name))\n",
      "    files=files.intersection(set(get_files('phantom_size', phantom_size)))\n",
      "    files=files.intersection(set(get_files('phantom_maximum', phantom_maximum)))\n",
      "    files=files.intersection(set(get_files('filter_size', filter_size)))\n",
      "    files=files.intersection(set(get_files('photons', photons)))\n",
      "    files=files.intersection(set(get_files('angles', angles_count,len)))\n",
      "    files = list(files)\n",
      "    return files\n",
      "\n",
      "def get_roi(img):\n",
      "    size =img.shape[0]\n",
      "    res = img[int(size*0.4):int(size*0.6),int(size*0.20):int(size*0.40)]\n",
      "    return res \n",
      "\n",
      "def show_tomo(phantom_name, phantom_size, phantom_maximum, filter_size, photons, angles_count ):\n",
      "    f = find_tomo_file(phantom_name, phantom_size, phantom_maximum, filter_size, photons, angles_count)\n",
      "    f=f[0]\n",
      "    print(f)\n",
      "    \n",
      "    plt.gray()\n",
      "    with h5py.File(f,'r') as h5f:\n",
      "        source_phantom = h5f['phantom'].value\n",
      "        fbp_rec_smooth = h5f['smoothed_fbp'].value\n",
      "        sart_rec = h5f['sart'].value\n",
      "        fbp_rec = h5f['fbp'].value\n",
      "    \n",
      "    source_phantom = pad_phantom(source_phantom)\n",
      "    \n",
      "    data = {'original': {'data':source_phantom, 'style':{'color':'r','linewidth':2}},\n",
      "        #'rec_sart3':rec_sart3,\n",
      "        'FBP (smoothed)': {'data':fbp_rec_smooth, 'style':{'color':'b','linewidth':2}},\n",
      "        'SART': {'data':sart_rec, 'style':{'color':'k','linewidth':2}},\n",
      "        'FBP': {'data':fbp_rec, 'style':{'color':'g','linewidth':2}}\n",
      "        }\n",
      "\n",
      "    size = data['original']['data'].shape[0]\n",
      "    x_range = range(int(size*0.4),int(size*0.6))\n",
      "    y_range = int(size*0.292)\n",
      "\n",
      "    plt.figure(figsize=(16,5))\n",
      "\n",
      "    plt.subplot(131)\n",
      "    for k,v in data.iteritems():\n",
      "        if 'style' in v:\n",
      "            kwords = v['style']\n",
      "        else:\n",
      "            kwords = {}\n",
      "\n",
      "        plt.plot(v['data'][x_range, y_range], label = k,**kwords)\n",
      "        plt.hold(True)\n",
      "\n",
      "    plt.grid()\n",
      "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
      "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
      "\n",
      "    plt.subplot(132)\n",
      "    orig_data = data['original']['data']\n",
      "    for k,v in data.iteritems():\n",
      "        if 'style' in v:\n",
      "            kwords = v['style']\n",
      "        else:\n",
      "            kwords = {}\n",
      "\n",
      "        if not k == 'original':\n",
      "            plt.plot((v['data']-orig_data)[x_range, y_range], \n",
      "                     label = '{} $\\sigma$ = {:0.3}'.format(k, image_std(v['data'],orig_data)),\n",
      "                     **kwords)\n",
      "            plt.hold(True)\n",
      "\n",
      "    plt.grid()\n",
      "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
      "           ncol=1, mode=\"expand\", borderaxespad=0.)\n",
      "\n",
      "    plt.subplot(133)\n",
      "    plt.imshow(np.rot90(data['original']['data'],3).T)\n",
      "    plt.hold(True)\n",
      "    if isinstance(y_range, int) or len(y_range) == 1:\n",
      "        x_plot = x_range\n",
      "        y_plot = y_range*np.ones_like(x_range)\n",
      "\n",
      "    elif isinstance(x_range, int) or len(x_range) == 1:\n",
      "        x_plot = x_range*np.ones_like(y_range)\n",
      "        y_plot = y_range\n",
      "    else:\n",
      "        x_plot = x_range\n",
      "        y_plot = y_range\n",
      "\n",
      "    #show position on phantom\n",
      "    plt.plot(y_plot,x_plot,'r', linewidth=2)\n",
      "    pylab.ylim([0,data['original']['data'].shape[0]])\n",
      "    pylab.xlim([0,data['original']['data'].shape[1]])\n",
      "    #plt.gca().set_axis_off()\n",
      "    \n",
      "    plt.figure(figsize=(15,8))\n",
      "    keys = ['original','SART', 'FBP']\n",
      "    for ik, k in enumerate(keys):\n",
      "        plt.subplot(100+10*len(keys)+ik)\n",
      "        plt.imshow(data[k]['data'])\n",
      "        plt.title(k)\n",
      "        plt.colorbar(orientation = 'horizontal')\n",
      "        \n",
      "    plt.figure(figsize=(15,8))\n",
      "    keys = ['SART', 'FBP']\n",
      "    for ik, k in enumerate(keys):\n",
      "        plt.subplot(100+10*len(keys)+ik)\n",
      "        plt.imshow(mssim.MSSIM(data['original']['data'], data[k]['data']))\n",
      "        plt.title('{}, ssim = {}'.format(k,mssim.SSIM(data['original']['data'], data[k]['data'])))\n",
      "        plt.colorbar(orientation = 'horizontal')\n",
      "    \n",
      "\n",
      "    plt.figure(figsize=(15,8))\n",
      "    keys = ['original','SART', 'FBP']\n",
      "    for ik, k in enumerate(keys):\n",
      "        plt.subplot(100+10*len(keys)+ik)\n",
      "        plt.imshow(get_roi(data[k]['data']))\n",
      "        plt.title(k)\n",
      "        plt.colorbar(orientation = 'horizontal')\n",
      "        \n",
      "w=interactive(show_tomo, \n",
      "              phantom_name = widgets.DropdownWidget(values = phantom_names, value=phantom_names[-1]) , \n",
      "              phantom_size = widgets.DropdownWidget(values = phantom_sizes),\n",
      "              phantom_maximum = widgets.DropdownWidget(values = phantom_maxima),\n",
      "              filter_size = widgets.DropdownWidget(values =filter_sizes),\n",
      "              photons = widgets.DropdownWidget(values = photons),\n",
      "              angles_count= widgets.DropdownWidget(values = angles_count));\n",
      "w"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_files = len(tomo_collection)   \n",
      "print('Total files: {}'.format(total_files))\n",
      "\n",
      "for itomo, tomo_file_name in enumerate(tomo_collection):\n",
      "    \n",
      "    tomo_record = tomo_collection[tomo_file_name]\n",
      "    \n",
      "    if not 'processing' in tomo_record :\n",
      "        tomo_record['processing'] = {}\n",
      "\n",
      "    with h5py.File(tomo_file_name, 'r') as h5f:\n",
      "        source_phantom = h5f['phantom'].value\n",
      "        fbp_rec_smooth = h5f['smoothed_fbp'].value\n",
      "        sart_rec = h5f['sart'].value\n",
      "        fbp_rec = h5f['fbp'].value\n",
      "    \n",
      "    #full images\n",
      "    paded_phantom = pad_phantom(source_phantom)      \n",
      "    tomo_record['processing']['sart_ssim'] = mssim.SSIM(paded_phantom, sart_rec)\n",
      "    tomo_record['processing']['fbp_ssim'] = mssim.SSIM(paded_phantom, fbp_rec)\n",
      "    tomo_record['processing']['fbp_smooth_ssim'] = mssim.SSIM(paded_phantom, fbp_rec_smooth)\n",
      "    \n",
      "    tomo_record['processing']['sart_std'] = image_std(paded_phantom, sart_rec)\n",
      "    tomo_record['processing']['fbp_std'] = image_std(paded_phantom, fbp_rec)\n",
      "    tomo_record['processing']['fbp_smooth_std'] = image_std(paded_phantom, fbp_rec_smooth)\n",
      "    \n",
      "    #roi images\n",
      "    roi_paded_phantom = get_roi(paded_phantom)\n",
      "    tomo_record['processing']['sart_ssim_roi'] = mssim.SSIM(roi_paded_phantom, get_roi(sart_rec))\n",
      "    tomo_record['processing']['fbp_ssim_roi'] = mssim.SSIM(roi_paded_phantom, get_roi(fbp_rec))\n",
      "    tomo_record['processing']['fbp_smooth_ssim_roi'] = mssim.SSIM(roi_paded_phantom, get_roi(fbp_rec_smooth))\n",
      "    \n",
      "    tomo_record['processing']['sart_std_roi'] = image_std(roi_paded_phantom, get_roi(sart_rec))\n",
      "    tomo_record['processing']['fbp_std_roi'] = image_std(roi_paded_phantom, get_roi(fbp_rec))\n",
      "    tomo_record['processing']['fbp_smooth_std_roi'] = image_std(roi_paded_phantom, get_roi(fbp_rec_smooth))\n",
      "    \n",
      "    if itomo%10 == 0 :\n",
      "        print(itomo, end=' ')\n",
      "    if itomo%250 == 0:\n",
      "        print('')\n",
      "        \n",
      "with open('tomo_collection.pkl','w') as f:        \n",
      "    pickle.dump(tomo_collection, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = []\n",
      "for tomo_rec in tomo_collection.itervalues():\n",
      "    proc = tomo_rec['processing']\n",
      "    data = [tomo_rec['phantom_name'],\n",
      "            tomo_rec['filter_size'],tomo_rec['phantom_maximum'],\n",
      "            tomo_rec['phantom_size'], tomo_rec['photons'], len(tomo_rec['angles']),\n",
      "            proc['sart_ssim'], proc['fbp_ssim'],proc['fbp_smooth_ssim'],\n",
      "            proc['sart_std'], proc['fbp_std'],proc['fbp_smooth_std'],\n",
      "            proc['sart_ssim_roi'], proc['fbp_ssim_roi'],proc['fbp_smooth_ssim_roi'],\n",
      "            proc['sart_std_roi'], proc['fbp_std_roi'],proc['fbp_smooth_std_roi']]\n",
      "    res.append(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_sl = filter(lambda x: x[0]=='modified_shepp_logan', res)\n",
      "data_sl = map(lambda x: x[1:], data_sl)\n",
      "\n",
      "data_sl = np.array(data_sl, dtype=np.float32)\n",
      "data_sl[isnan(data_sl)] = 0\n",
      "# data_sl = np.array(data_sl, dtype = [\n",
      "#     ('filter_size',np.float32),('phantom_maximum',np.float32),('phantom_size',np.float32),\n",
      "#     ('photons',np.float32),('angles',np.float32),('sart_ssim',np.float32),\n",
      "#     ('fbp_ssim',np.float32),('fbp_smooth_ssim',np.float32),('sart_std',np.float32),('fbp_std',np.float32),\n",
      "#     ('fbp_smooth_std',np.float32),('sart_ssim_roi',np.float32),('fbp_ssim_roi',np.float32),\n",
      "#     ('fbp_smooth_ssim_roi',np.float32),('sart_std_roi',np.float32),('fbp_std_roi',np.float32),\n",
      "#     ('fbp_smooth_std_roi',np.float32)])\n",
      "print(data_sl.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s= data_sl.copy()\n",
      "s = s[s[:,0]==0] # set filter_size=0\n",
      "s = s[isclose(s[:,1],1)] # set phantom_maximum=1\n",
      "s = s[isclose(s[:,2],512)] # set phantom_size=512\n",
      "#s = s[isclose(s[:,3],0)] # set photons=0\n",
      "\n",
      "filter_sizes = s[:,0]\n",
      "phantom_maxima = s[:,1]\n",
      "phantom_size = s[:,2]\n",
      "photons = s[:,3]\n",
      "angles = s[:,4]\n",
      "sart_ssim = s[:,5]\n",
      "fbp_ssim = s[:,6]\n",
      "fbp_smooth_ssim = s[:,7]\n",
      "sart_std = s[:,8]\n",
      "fbp_std = s[:,9]\n",
      "fbp_smooth_std = s[:,10]\n",
      "sart_ssim_roi = s[:,11]\n",
      "fbp_ssim_roi = s[:,12]\n",
      "fbp_smooth_ssim_roi = s[:,13]\n",
      "sart_std_roi = s[:,14]\n",
      "fbp_std_roi = s[:,15]\n",
      "fbp_smooth_std_roi = s[:,16]\n",
      "\n",
      "print('Unique filter_size {}'.format(np.unique(filter_sizes)))\n",
      "print('Unique phantom_maximum {}'.format(np.unique(phantom_maxima)))\n",
      "print('Unique phantom_size {}'.format(np.unique(phantom_size)))\n",
      "print('Unique photons {}'.format(np.unique(photons)))\n",
      "print('Unique angles {}'.format(np.unique(angles)))\n",
      "\n",
      "print(s.shape)\n",
      "\n",
      "plt.figure(figsize=(7,10))\n",
      "plt.subplot(311)\n",
      "for p in np.unique(photons):\n",
      "    x = angles[photons == p]\n",
      "    y = sart_ssim[photons== p]\n",
      "    sort_args = np.argsort(x)\n",
      "    plt.plot(x[sort_args], y[sort_args], lw=2, label = 'SART at Photons {}'.format(p))\n",
      "    plt.ylim([0,1])\n",
      "    plt.hold(True)\n",
      "plt.grid()\n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "plt.xlabel('Angeles count')\n",
      "plt.ylabel('SSIM')\n",
      "\n",
      "plt.subplot(312)    \n",
      "for p in np.unique(photons):\n",
      "    x = angles[photons == p]\n",
      "    y = fbp_ssim[photons== p]\n",
      "    sort_args = np.argsort(x)\n",
      "    plt.plot(x[sort_args], y[sort_args], lw=2, label = 'FBP at Photons {}'.format(p))\n",
      "    plt.ylim([0,1])\n",
      "    plt.hold(True)\n",
      "plt.grid()\n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "plt.xlabel('Angeles count')\n",
      "plt.ylabel('SSIM')\n",
      "\n",
      "plt.subplot(313)    \n",
      "for p in np.unique(photons):\n",
      "    x = angles[photons == p]\n",
      "    y = fbp_smooth_ssim[photons== p]\n",
      "    sort_args = np.argsort(x)\n",
      "    plt.plot(x[sort_args], y[sort_args], lw=2, label = 'FBP (Smoothed) at Photons {}'.format(p))\n",
      "    plt.ylim([0,1])\n",
      "    plt.hold(True)\n",
      "plt.grid()    \n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "plt.xlabel('Angeles count')\n",
      "plt.ylabel('SSIM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s= data_sl.copy()\n",
      "s = s[s[:,0]==5] # set filter_size=0\n",
      "s = s[isclose(s[:,1],1)] # set phantom_maximum=1\n",
      "s = s[isclose(s[:,2],512)] # set phantom_size=512\n",
      "#s = s[isclose(s[:,3],0)] # set photons=0\n",
      "\n",
      "filter_sizes = s[:,0]\n",
      "phantom_maxima = s[:,1]\n",
      "phantom_size = s[:,2]\n",
      "photons = s[:,3]\n",
      "angles = s[:,4]\n",
      "sart_ssim = s[:,5]\n",
      "fbp_ssim = s[:,6]\n",
      "fbp_smooth_ssim = s[:,7]\n",
      "sart_std = s[:,8]\n",
      "fbp_std = s[:,9]\n",
      "fbp_smooth_std = s[:,10]\n",
      "sart_ssim_roi = s[:,11]\n",
      "fbp_ssim_roi = s[:,12]\n",
      "fbp_smooth_ssim_roi = s[:,13]\n",
      "sart_std_roi = s[:,14]\n",
      "fbp_std_roi = s[:,15]\n",
      "fbp_smooth_std_roi = s[:,16]\n",
      "\n",
      "print('Unique filter_size {}'.format(np.unique(filter_sizes)))\n",
      "print('Unique phantom_maximum {}'.format(np.unique(phantom_maxima)))\n",
      "print('Unique phantom_size {}'.format(np.unique(phantom_size)))\n",
      "print('Unique photons {}'.format(np.unique(photons)))\n",
      "print('Unique angles {}'.format(np.unique(angles)))\n",
      "\n",
      "print(s.shape)\n",
      "\n",
      "plt.figure(figsize=(7,10))\n",
      "plt.subplot(311)\n",
      "for p in np.unique(photons):\n",
      "    x = angles[photons == p]\n",
      "    y = sart_ssim[photons== p]\n",
      "    sort_args = np.argsort(x)\n",
      "    plt.plot(x[sort_args], y[sort_args], lw=2, label = 'SART at Photons {}'.format(p))\n",
      "    plt.ylim([0,1])\n",
      "    plt.hold(True)\n",
      "plt.grid()\n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "plt.xlabel('Angeles count')\n",
      "plt.ylabel('SSIM')\n",
      "\n",
      "plt.subplot(312)    \n",
      "for p in np.unique(photons):\n",
      "    x = angles[photons == p]\n",
      "    y = fbp_ssim[photons== p]\n",
      "    sort_args = np.argsort(x)\n",
      "    plt.plot(x[sort_args], y[sort_args], lw=2, label = 'FBP at Photons {}'.format(p))\n",
      "    plt.ylim([0,1])\n",
      "    plt.hold(True)\n",
      "plt.grid()\n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "plt.xlabel('Angeles count')\n",
      "plt.ylabel('SSIM')\n",
      "\n",
      "plt.subplot(313)    \n",
      "for p in np.unique(photons):\n",
      "    x = angles[photons == p]\n",
      "    y = fbp_smooth_ssim[photons== p]\n",
      "    sort_args = np.argsort(x)\n",
      "    plt.plot(x[sort_args], y[sort_args], lw=2, label = 'FBP (Smoothed) at Photons {}'.format(p))\n",
      "    plt.ylim([0,1])\n",
      "    plt.hold(True)\n",
      "plt.grid()    \n",
      "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
      "plt.xlabel('Angeles count')\n",
      "plt.ylabel('SSIM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}